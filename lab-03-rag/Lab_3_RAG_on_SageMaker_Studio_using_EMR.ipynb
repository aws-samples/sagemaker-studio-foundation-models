{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6268e06-20fb-4ad7-bd47-5d51f7e59252",
   "metadata": {},
   "source": [
    "# Lab 03. Build Retrival Augmented Generation System using Amazon EMR Spark Distributed Processing and OpeSearch Vector Database "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c7006-3446-41a6-a41a-d76875062d70",
   "metadata": {},
   "source": [
    "In this notebook we demonstrate how you can build a Retrival Augmented Generation System using the following components,\n",
    "1. Embedding Model: `all-MiniLM-L6-v2`\n",
    "2. Text Generation Model: `meta-/llama2-7b-chat`\n",
    "3. Vector Database: OpenSearch as Vector Database to store embeddings\n",
    "4. StreamLit UI: A Chat Interface to talk to your documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafa23c1-aed3-41d8-bf4c-2e0ed9e3dcb0",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFDDDD; border-left: 5px solid red; padding: 10px; color: black;\">\n",
    "    <strong>Kernel:</strong> Spark Analytics 2.0 [SparkMagic PySpark] <strong>Instance Type:</strong> ml.t3.medium\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf4391-89f7-424b-839e-5d92127aa83b",
   "metadata": {},
   "source": [
    "## Connect to an Existing EMR Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c69a9a-6181-42e8-9b12-d0554b530e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext sagemaker_studio_analytics_extension.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e083fe-bd83-42bb-b75b-886263d1ee25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4328a06-6afd-4f0e-8b8f-eb86162705a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "!echo \"Your EMR Cluster ID ---> $(aws emr list-clusters | jq '.Clusters[0].Id')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf19ff-5da9-48d7-948a-f8f87054fea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sm_analytics emr connect --verify-certificate False --cluster-id j-3FIXE21RQG8VM --auth-type None --language python  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb60b5-97e5-460a-8049-c8ecbbe6b810",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload Files from Local to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee95b3-53d3-4d44-9c6a-11fa2d4efeff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "!python3 -m pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183cdac4-ca2e-4eee-9939-8b4c3c64af78",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "!python3 -m pip install sagemaker==2.192.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3b0d4-0e93-45ab-ab2c-b18e3bfd8853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "import glob\n",
    "import boto3\n",
    "import sagemaker\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d33fd-40c4-4d3e-bab3-df14978cf658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "sess = sagemaker.Session()\n",
    "default_bucket = sess.default_bucket()\n",
    "s3_client = boto3.client(\"s3\")\n",
    "print(f\"Using default bucket ---> {default_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6690bd-76b5-40e9-acf9-98bb43f19733",
   "metadata": {},
   "source": [
    "A few sample files are available in directory under ./AWSGuides/, these are sample documents we'll be using to build our RAG application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb76b3-e96b-4b70-bd12-5d3dacae6514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "def upload_raw_pdf_files_to_bucket(destination_bucket, destination_prefix, raw_pdf_files):\n",
    "    \n",
    "    print(f\"Uploading ---> {len(raw_pdf_files)} files!\")\n",
    "    \n",
    "    uploaded_file_s3uris = []\n",
    "    for pdf_file in tqdm(raw_pdf_files, total=len(raw_pdf_files)):\n",
    "        pdf_fname = os.path.basename(pdf_file).replace(\",\", \"\").replace(\" \", \"-\")\n",
    "        \n",
    "        pdf_dest_prefix = os.path.join(destination_prefix, pdf_fname)\n",
    "        \n",
    "        s3_client.upload_file(\n",
    "            pdf_file, \n",
    "            destination_bucket, \n",
    "            pdf_dest_prefix\n",
    "        )\n",
    "        uploaded_file_s3uris.append(f\"s3://{destination_bucket}/{pdf_dest_prefix}\")\n",
    "    \n",
    "    return uploaded_file_s3uris\n",
    "\n",
    "pdf_files_to_upload = glob.glob(\"./AWSGuides/*.pdf\")\n",
    "\n",
    "destination_prefix = \"Lab03/raw-pdfs\"\n",
    "\n",
    "files_paths_in_s3 = upload_raw_pdf_files_to_bucket(\n",
    "    destination_bucket=default_bucket, \n",
    "    destination_prefix=destination_prefix,\n",
    "    raw_pdf_files=pdf_files_to_upload\n",
    ")\n",
    "\n",
    "print(f\"Uploaded files to ---> {files_paths_in_s3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b03af6-cea3-46b7-8130-e7a343fa5292",
   "metadata": {},
   "source": [
    "Let's send these variables from our local instance to Pyspark Primary node using a simple \n",
    "\n",
    "`%%send_to_spark` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b1188-b923-4393-8a79-35c9473af586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%send_to_spark -i destination_prefix -t str -n SRC_FILE_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7088e24-31b6-4e1b-8d07-7145c2551df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%send_to_spark -i default_bucket -t str -n SRC_BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb76b80-4ffa-453d-abc4-d63e84ef45f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lets Convert PDF into Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24cf1a1-a2ef-4e44-b95a-9d4958cac47d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9adac1-5351-4439-af37-bab508ecdb8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Source bucket and prefix to read pdf files ---> {SRC_BUCKET_NAME} {SRC_FILE_PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a4611-8edb-446a-97f3-b34562afdfc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_files_in_s3_bucket_prefix(bucket_name, prefix):\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Paginate through the objects in the specified bucket and prefix, and collect all keys (file paths)\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "    file_paths = []\n",
    "    for page in page_iterator:\n",
    "        if \"Contents\" in page:\n",
    "            for obj in page[\"Contents\"]:\n",
    "                if os.path.basename(obj[\"Key\"]):\n",
    "                    file_paths.append(obj[\"Key\"])\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "all_pdf_files = list_files_in_s3_bucket_prefix(\n",
    "    bucket_name=SRC_BUCKET_NAME, \n",
    "    prefix=SRC_FILE_PREFIX\n",
    ")\n",
    "print(f\"Found {len(all_pdf_files)} files ---> {all_pdf_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca227df-c358-4074-bd80-fbbe15b850ae",
   "metadata": {},
   "source": [
    "Let's prep a list to process files along with bucket names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20c47e-ef4d-44b9-b0e4-64fda6f4358e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pdf_files = [(SRC_BUCKET_NAME, fpath) for fpath in all_pdf_files]\n",
    "type(all_pdf_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20da11-468b-4038-9605-c1bc86fec182",
   "metadata": {},
   "source": [
    "Let's convert our list to a spark RDD for parallelization of our list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2430d20-4b34-46fc-b939-9071a0396b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdfs_rdd = spark.sparkContext.parallelize(all_pdf_files)\n",
    "type(pdfs_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f3c93-6c8b-45a1-9e3b-973efc71457e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Each code node reaches out a pdf file from our list, downloads the pdf file into memory and returns a PyPDF2 class reference for downstream workloads\n",
    "\n",
    "![EMR Read PDFs into Memory](media/EMR-Doc-Read.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b0c93-4f4c-4870-a819-216358d863ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_pdf_from_s3_into_memory(row):\n",
    "    \"\"\"\n",
    "    Load a PDF file from an S3 bucket directly into memory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src_bucket_name, src_file_key = row \n",
    "        s3 = boto3.client('s3')\n",
    "        pdf_file = io.BytesIO()\n",
    "        s3.download_fileobj(src_bucket_name, src_file_key, pdf_file)\n",
    "        pdf_file.seek(0)\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "        return (src_file_key, pdf_reader, len(pdf_reader.pages))\n",
    "    \n",
    "    except Exception as e:    \n",
    "        return (os.path.basename(src_file_key), str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536e2f8-c27c-46de-8a1f-c0d24fabb55e",
   "metadata": {},
   "source": [
    "Let's concurrently load pdf files into memory using rdd map and collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ff3c4-665a-4d9d-8c86-016c78a24e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdfs_in_memory = pdfs_rdd.map(load_pdf_from_s3_into_memory).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11628e-a048-43bc-8d36-e9cdfa5b7e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"all pdfs combined there are ---> {sum([pg_num for _, _, pg_num in pdfs_in_memory])} pages to process!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822bd81-bf8e-43ab-94dd-4185750baff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDocument:\n",
    "    def __init__(self, text, path, number):\n",
    "        self.page_content = text\n",
    "        self.metadata = {\n",
    "            'source': path, \n",
    "            'page': number  \n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This method is for representing the object in a way thatâ€™s clear to a human (also can be used for debugging)\n",
    "        return f\"Document(page_content='{self.page_content}', metadata={self.metadata})\"\n",
    "\n",
    "    # Optionally, if you need a string representation of the instance that is more user-friendly, \n",
    "    # you can implement the __str__ method\n",
    "    def __str__(self):\n",
    "        return f\"Page Content: {self.page_content}\\nSource: {self.metadata['source']}\\nPage Number: {self.metadata['page']}\"\n",
    "    \n",
    "def extract_text_from_pdf_reader(row):\n",
    "    \"\"\" \n",
    "    Extract text from a page of the document \n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc_path, page_num = row\n",
    "        page_text = global_pdfs_in_mem_dict[doc_path].pages[page_num].extract_text()\n",
    "        return page_text, doc_path, page_num\n",
    "    except Exception as e:\n",
    "        return str(e), doc_path, page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2aca6-3ef8-4620-b70d-b4fd99340c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_pdfs_in_mem_dict = {_key: pdf_reader for _key, pdf_reader, _ in pdfs_in_memory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709d8df-5cdf-48be-9f16-93e5b7a8f031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_instances = []\n",
    "for (file_src, _, page_count) in pdfs_in_memory:\n",
    "    for pg_num in range(page_count):\n",
    "        docs_instances.append((file_src, pg_num))\n",
    "print(f\"Created {len(docs_instances)} parallel instances to process!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e3544-30c3-40f1-be45-84d3fc9d9133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_instances_rdd = spark.sparkContext.parallelize(docs_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c5d70-cfb8-4d34-86a6-0091ee8a2a20",
   "metadata": {},
   "source": [
    "Every PDF document has 'n' pages to process, this task can be executed in a parallel fashion using Spark Processing. \n",
    "\n",
    "Each Document is split page by page, each page from a global reference of in memory pdfs.\n",
    "\n",
    "![PageLevelProcessingEMRPDFtoTxt](media/PageLevelProcessingEMRPDFtoTxt.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19adf08d-898a-4d29-ab3a-b879aed47bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = docs_instances_rdd.map(extract_text_from_pdf_reader).collect()\n",
    "documents_custom = [\n",
    "    CustomDocument(text=text, path=doc_source, number=page_num) \n",
    "    for text, doc_source, page_num in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c647d26-7e0a-4bf1-ae1c-91f543d431a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents_custom[121]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9a7d8-8ac5-4313-b255-abd779ac7277",
   "metadata": {},
   "source": [
    "We split pages using a reference chunk size, chunk size is an experimental value. To learn more about chunk size and how RecursiveCharacterTextSplitter, see: https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6789c4-9b7c-4fe3-93e3-2533513ea404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=750,\n",
    "    chunk_overlap=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d41678-45aa-4731-9429-a5a00c1e5cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = global_text_splitter.split_documents(documents_custom)\n",
    "print(f\"Total number of docs after split {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb2184-e098-4582-90ec-ddc0fea5916a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(docs[2695])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40185c-15e3-4cbd-9d82-30af418d1378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(input_text_sample):\n",
    "    \n",
    "    assert isinstance(input_text_sample, str), f\"Input must be a single string but found \" \n",
    "    \n",
    "    lambda_client = boto3.client('lambda', region_name='us-west-2') \n",
    "\n",
    "    # Prepare the data to send to the Lambda function\n",
    "    data = {\n",
    "        \"input\": input_text_sample\n",
    "    }\n",
    "\n",
    "    # Invoke the Lambda function\n",
    "    response = lambda_client.invoke(\n",
    "        FunctionName=\"invokeEmbeddingEndpoint\",\n",
    "        InvocationType=\"RequestResponse\",\n",
    "        Payload=json.dumps(data)\n",
    "    )\n",
    "\n",
    "    # Decode and load the response payload\n",
    "    response_payload = json.loads(response['Payload'].read().decode(\"utf-8\"))\n",
    "\n",
    "    # Extract status and embeddings from the response\n",
    "    status_code, embeddings = int(response_payload['statusCode']), json.loads(response_payload['body'])\n",
    "\n",
    "    return status_code, embeddings\n",
    "    \n",
    "class EmbeddingsGenerator:\n",
    "    \n",
    "    @staticmethod\n",
    "    def embed_documents(input_text, normalize=True):\n",
    "        \"\"\"\n",
    "        Generate embeddings for the provided text, invoking a Lambda function.\n",
    "        \"\"\"\n",
    "        assert isinstance(input_text, list), \"Input type must me list to embed_documents function\"\n",
    "        \n",
    "        input_text_rdd = spark.sparkContext.parallelize(input_text)\n",
    "        \n",
    "        embeddings_generated = input_text_rdd.map(generate_embeddings).collect()\n",
    "        \n",
    "        embedding_response = []\n",
    "        for s_code, embeddings in embeddings_generated:\n",
    "            if s_code == 200:\n",
    "                embedding_response.append(embeddings)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        return embedding_response\n",
    "    \n",
    "    @staticmethod\n",
    "    def embed_query(input_text):\n",
    "        status_code, embedding = generate_embeddings(input_text)\n",
    "        if status_code == 200:\n",
    "            return embedding\n",
    "        else: \n",
    "            None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81eb0d-e91a-450c-b841-371f1297a28c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_code, sample_sentence_embedding = generate_embeddings(docs[1000].page_content)\n",
    "print(f\"Status {response_code}, Embedding size of the document --->\", len(sample_sentence_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b0e5b-9705-4a18-8368-15618ea4146c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "INDEX_NAME_OSE = \"amz-guides-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac1b62-9fbe-4c17-a3c7-c0d23354176a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%send_to_spark -i INDEX_NAME_OSE -t str -n INDEX_NAME_OSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce389bf-1122-4be3-b9dd-2afa03fc4b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name, region_name=\"us-west-2\"):\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "    get_secret_value_response = client.get_secret_value(\n",
    "        SecretId=secret_name\n",
    "    )\n",
    "    secrets = json.loads(get_secret_value_response['SecretString'])\n",
    "    user = secrets['username']\n",
    "    pwd = secrets['password']\n",
    "    return user, pwd\n",
    "\n",
    "# Use the function\n",
    "my_secret_name = \"OpenSearchSecret-workshop-studio-cfn\"  # Replace with your secret name\n",
    "my_region_name = \"us-west-2\"     # Replace with your AWS region\n",
    "user, pwd = get_secret(my_secret_name, my_region_name)\n",
    "print(f\"Session user and pwd ---> \", user, pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebbb0ce-4fbf-49b7-b7a9-2126e6b01a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = EmbeddingsGenerator.embed_documents([d.page_content for d in docs[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1cba2c-a5ba-4a69-9771-3655d87f5f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203689c0-015b-4700-8d56-3083e97d4969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "docsearch = OpenSearchVectorSearch.from_documents(\n",
    "    docs[:100], \n",
    "    EmbeddingsGenerator, \n",
    "    opensearch_url=\"https://search-opensearchservi-ol9kboy2sp4p-o62szzg7yeeufr3mi26nanxfke.us-west-2.es.amazonaws.com\",\n",
    "    bulk_size=len(docs),\n",
    "    http_auth=(\"admin\", \"Admin123-\"),\n",
    "    index_name=INDEX_NAME_OSE,\n",
    "    engine=\"faiss\"\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Total Time for ingestion: {round(end - start, 2)} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ef10c-a50e-4c01-b647-befb7e1f4c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What is a SageMaker\"\n",
    "sample_responses = docsearch.similarity_search(\n",
    "    query, \n",
    "    k=5, \n",
    "    space_type=\"cosineSimilarity\", \n",
    "    search_type=\"painless_scripting\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fecfc5-f0cd-4064-82c8-aff9f6b3013c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_responses[-1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c564f-4f9b-4f5e-9d90-37f51bc27979",
   "metadata": {},
   "source": [
    "## Putting it All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5adaca-a9eb-486f-9f08-84cf2f0f9bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "!python3 -m pip install -q opensearch-py==2.3.2 langchain==0.0.310 typing_extensions==4.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95bafd-e975-436a-9622-1aa1d36b9fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "import boto3\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    def __init__(self):\n",
    "        self.lambda_client = boto3.client('lambda', region_name='us-west-2')\n",
    "    \n",
    "    def embed_query(self, input_text_sample):\n",
    "        \"\"\"Generate embeddings for the input text.\"\"\"\n",
    "        \n",
    "        # Prepare the data to send to the Lambda function.\n",
    "        data = {\"input\": [input_text_sample]}\n",
    "\n",
    "        # Invoke the Lambda function.\n",
    "        response = self.lambda_client.invoke(\n",
    "            FunctionName=\"InvokeEndpoint\",\n",
    "            InvocationType=\"RequestResponse\",\n",
    "            Payload=json.dumps(data)\n",
    "        )\n",
    "\n",
    "        # Decode and load the response payload.\n",
    "        response_payload = json.loads(response['Payload'].read().decode(\"utf-8\"))\n",
    "\n",
    "        # Extract status and embeddings from the response.\n",
    "        status_code, embeddings = int(response_payload['statusCode']), json.loads(response_payload['body'])\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "embedding_generator = EmbeddingGenerator()\n",
    "\n",
    "docsearch = OpenSearchVectorSearch(\n",
    "    index_name=INDEX_NAME_OSE,\n",
    "    embedding_function=embedding_generator,\n",
    "    opensearch_url=\"https://search-opensearchservi-ol9kboy2sp4p-o62szzg7yeeufr3mi26nanxfke.us-west-2.es.amazonaws.com\",\n",
    "    http_auth=(\"admin\", \"Admin123-\"),\n",
    "    engine=\"faiss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3526c1b2-af46-410e-922a-f1687af1acd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "import re\n",
    "import json\n",
    "from typing import Dict\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.llms import SagemakerEndpoint\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    \n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        \n",
    "        pattern = r\"(QUESTION:\\n)(.*?)(\\n\\n)\"\n",
    "        \n",
    "        match = re.search(pattern, prompt, re.DOTALL)\n",
    "        \n",
    "        # question_block = match.group(0)\n",
    "        query_only = match.group(2)\n",
    "        \n",
    "        modified_prompt = re.sub(pattern, '', prompt, flags=re.DOTALL)\n",
    "        \n",
    "        body = {\n",
    "            \"inputs\": [\n",
    "                [\n",
    "                     {\n",
    "                         \"role\": \"system\", \n",
    "                         \"content\": modified_prompt\n",
    "                     },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": query_only\n",
    "                    },\n",
    "                ]   \n",
    "            ], \n",
    "            \"parameters\": model_kwargs\n",
    "        }\n",
    "        input_str = json.dumps(body)\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        system_response = response_json[0]['generation']['content']\n",
    "        return system_response.strip()\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "\n",
    "llm_sm_ep = SagemakerEndpoint(\n",
    "    endpoint_name=\"jumpstart-dft-meta-textgeneration-llama-2-7b-f\", \n",
    "    region_name=\"us-east-1\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512, \n",
    "        \"top_p\": 1.0, \n",
    "        \"temperature\": 0.1, \n",
    "        \"return_full_text\": False\n",
    "    },\n",
    "    content_handler=content_handler,\n",
    "    endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf50f9e-f64d-4bf6-9bd4-d8c924da06ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the following QUESTION based on the CONTEXT\n",
    "given. If you do not know the answer and the CONTEXT doesn't\n",
    "contain the answer truthfully say \"I don't know\".\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template, \n",
    "    input_variables=['context', 'question']\n",
    ")\n",
    "\n",
    "llm_qa_smep_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_sm_ep,\n",
    "    chain_type='stuff',\n",
    "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 10, \"space_type\": \"cosineSimilarity\", \"space_type\": \"painless_scripting\"}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")\n",
    "\n",
    "\n",
    "def pretty_print(chain_op):\n",
    "    question = chain_op['query']\n",
    "    \n",
    "    response = chain_op['result']\n",
    "    \n",
    "    sources = \"\\n\".join([f\"-{src.metadata['source'].split('/')[-1]} (page: {src.metadata['page']})\" for src in chain_op['source_documents']])\n",
    "    \n",
    "    stdout = f\"\"\"Question:\\n> {question}\\n\\n================\\nSystem:\\n> {response}\\n\\n================\\nSources:\\n{sources}\n",
    "    \"\"\"\n",
    "    print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c24205-1c2b-49f3-a36d-af213ee12a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"What is a SageMaker Training job and how do you run it?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc9db4-5897-4227-a38b-b427eae71e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"What types of instances are supported for Training Job?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c62707-02ec-42c3-9a8b-ade8f45670e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How to install packages on EC2 instances using Command line?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d59090-4017-4f27-a5a3-9e72f84a049d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How to Create a Training Job using Boto3 SDK?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c615cd-1245-4cc0-9391-164102395efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How can I deploy a model to SageMaker Hosting service?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8cec4-7304-4c5f-93c7-1d77b041c31d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How do I validate a model using boto3 sdk and visualize results using matplotlib library?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651df026-405c-4a4a-9530-8c252a703a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How can I use the console to add a git repository to my SageMaker account?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1face8fd-d580-4907-bb2f-425d5b8a4486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "SparkMagic PySpark (SparkAnalytics 2.0)",
   "language": "python",
   "name": "conda-env-sm_sparkmagic-pysparkkernel__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-sparkanalytics-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
