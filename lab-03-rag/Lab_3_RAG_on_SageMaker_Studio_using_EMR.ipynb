{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6268e06-20fb-4ad7-bd47-5d51f7e59252",
   "metadata": {},
   "source": [
    "# Build Retrival Augmented Generation System using Amazon EMR Spark Distributed Processing and OpeSearch Vector Database "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c7006-3446-41a6-a41a-d76875062d70",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrage users how to build a Retrival Augmented Generation (RAG) system using Mini-lm embeding model and `Llama2` Text Generation LLM.\n",
    "\n",
    "We're leveraging OpenSearch Vector DB to store and retrive document embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf4391-89f7-424b-839e-5d92127aa83b",
   "metadata": {},
   "source": [
    "## Connect to an Existing EMR Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dbf19ff-5da9-48d7-948a-f8f87054fea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read emr cluster(j-NVBGPRZK5XVX) details\n",
      "Initiating EMR connection..\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1698298206599_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-20-29.ec2.internal:20888/proxy/application_1698298206599_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-20-30.ec2.internal:8042/node/containerlogs/container_1698298206599_0003_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "{\"namespace\": \"sagemaker-analytics\", \"cluster_id\": \"j-NVBGPRZK5XVX\", \"error_message\": null, \"success\": true, \"service\": \"emr\", \"operation\": \"connect\"}\n"
     ]
    }
   ],
   "source": [
    "%load_ext sagemaker_studio_analytics_extension.magics\n",
    "%sm_analytics emr connect --verify-certificate False --cluster-id j-NVBGPRZK5XVX --auth-type None --language python  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb60b5-97e5-460a-8049-c8ecbbe6b810",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Upload Files from Local to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a3b0d4-0e93-45ab-ab2c-b18e3bfd8853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "import glob\n",
    "import boto3\n",
    "import pikepdf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92cb76b3-e96b-4b70-bd12-5d3dacae6514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files ---> 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "pdf_files = glob.glob(\"./AWSGuides/*.pdf\")\n",
    "print(f\"Total files ---> {len(pdf_files)}\")\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "for pdf_file in tqdm(pdf_files, total=len(pdf_files)):\n",
    "    _filename = os.path.basename(pdf_file)\n",
    "    _filename = _filename.replace(\",\", \"\").replace(\" \", \"-\")\n",
    "    s3_client.upload_file(\n",
    "        pdf_file, \n",
    "        \"sagemaker-us-east-1-280318901237\", \n",
    "        os.path.join(\"Lab03\", \"raw-pdfs\", _filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb76b80-4ffa-453d-abc4-d63e84ef45f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lets Convert PDF into Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a24cf1a1-a2ef-4e44-b95a-9d4958cac47d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9adac1-5351-4439-af37-bab508ecdb8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SRC_BUCKET_NAME = \"sagemaker-us-east-1-280318901237\"\n",
    "SRC_FILE_PREFIX = \"Lab03/raw-pdfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc3a4611-8edb-446a-97f3-b34562afdfc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 files!"
     ]
    }
   ],
   "source": [
    "def list_files_in_s3_bucket_prefix(bucket_name, prefix):\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Paginate through the objects in the specified bucket and prefix, and collect all keys (file paths)\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "    file_paths = []\n",
    "    for page in page_iterator:\n",
    "        if \"Contents\" in page:\n",
    "            for obj in page[\"Contents\"]:\n",
    "                if os.path.basename(obj[\"Key\"]):\n",
    "                    file_paths.append(obj[\"Key\"])\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "all_pdf_files = list_files_in_s3_bucket_prefix(\n",
    "    bucket_name=SRC_BUCKET_NAME, \n",
    "    prefix=SRC_FILE_PREFIX\n",
    ")\n",
    "print(f\"Found {len(all_pdf_files)} files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c20c47e-ef4d-44b9-b0e4-64fda6f4358e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_pdf_files = [(SRC_BUCKET_NAME, fpath) for fpath in all_pdf_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2430d20-4b34-46fc-b939-9071a0396b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdfs_rdd = spark.sparkContext.parallelize(all_pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af4b0c93-4f4c-4870-a819-216358d863ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_pdf_from_s3(row):\n",
    "    \"\"\"\n",
    "    Load a PDF file from an S3 bucket into memory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src_bucket_name, src_file_key = row \n",
    "        s3 = boto3.client('s3')\n",
    "        pdf_file = io.BytesIO()\n",
    "        s3.download_fileobj(src_bucket_name, src_file_key, pdf_file)\n",
    "        pdf_file.seek(0)\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "        return (src_file_key, pdf_reader, len(pdf_reader.pages))\n",
    "    \n",
    "    except Exception as e:    \n",
    "        return (os.path.basename(src_file_key), str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "387ff3c4-665a-4d9d-8c86-016c78a24e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdfs_in_memory = pdfs_rdd.map(load_pdf_from_s3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0422d15-831d-4976-9f2b-ebb2d2a3f5c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lab03/raw-pdfs/AWSLambdaDeveloperGuide.pdf', <PyPDF2._reader.PdfReader object at 0x7f7608188040>, 81), ('Lab03/raw-pdfs/AmazonSageMakerDeveloperGuide.pdf', <PyPDF2._reader.PdfReader object at 0x7f7608188d60>, 1055), ('Lab03/raw-pdfs/EC2DeveloperGuide.pdf', <PyPDF2._reader.PdfReader object at 0x7f7623eae4f0>, 698), ('Lab03/raw-pdfs/EMRManagementGuide.pdf', <PyPDF2._reader.PdfReader object at 0x7f761c658040>, 918), ('Lab03/raw-pdfs/S3DeveloperGuide.pdf', <PyPDF2._reader.PdfReader object at 0x7f761bf9e040>, 553)]"
     ]
    }
   ],
   "source": [
    "pdfs_in_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef11628e-a048-43bc-8d36-e9cdfa5b7e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3305"
     ]
    }
   ],
   "source": [
    "sum([pg_num for _, _, pg_num in pdfs_in_memory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c822bd81-bf8e-43ab-94dd-4185750baff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomDocument:\n",
    "    def __init__(self, text, path, number):\n",
    "        self.page_content = text\n",
    "        self.metadata = {\n",
    "            'source': path, \n",
    "            'page': number  \n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This method is for representing the object in a way that’s clear to a human (also can be used for debugging)\n",
    "        return f\"Document(page_content='{self.page_content}', metadata={self.metadata})\"\n",
    "\n",
    "    # Optionally, if you need a string representation of the instance that is more user-friendly, \n",
    "    # you can implement the __str__ method\n",
    "    def __str__(self):\n",
    "        return f\"Page Content: {self.page_content}\\nSource: {self.metadata['source']}\\nPage Number: {self.metadata['page']}\"\n",
    "    \n",
    "def extract_text_from_pdf_reader(row):\n",
    "    \"\"\" \n",
    "    Extract text from a page of the document \n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc_path, page_num = row\n",
    "        page_text = global_pdfs_in_mem_dict[doc_path].pages[page_num].extract_text()\n",
    "        return page_text, doc_path, page_num\n",
    "    except Exception as e:\n",
    "        return str(e), doc_path, page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44a2aca6-3ef8-4620-b70d-b4fd99340c71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_pdfs_in_mem_dict = {_key: pdf_reader for _key, pdf_reader, _ in pdfs_in_memory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6709d8df-5cdf-48be-9f16-93e5b7a8f031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3305 parallel instances to process!"
     ]
    }
   ],
   "source": [
    "docs_instances = []\n",
    "for (file_src, _, page_count) in pdfs_in_memory:\n",
    "    for pg_num in range(page_count):\n",
    "        docs_instances.append((file_src, pg_num))\n",
    "print(f\"Created {len(docs_instances)} parallel instances to process!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "364e3544-30c3-40f1-be45-84d3fc9d9133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_instances_rdd = spark.sparkContext.parallelize(docs_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19adf08d-898a-4d29-ab3a-b879aed47bde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = docs_instances_rdd.map(extract_text_from_pdf_reader).collect()\n",
    "documents_custom = [\n",
    "    CustomDocument(text=text, path=doc_source, number=page_num) \n",
    "    for text, doc_source, page_num in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c647d26-7e0a-4bf1-ae1c-91f543d431a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(page_content='Amazon SageMaker Developer Guide\n",
      "Step 7.2: Validate a Model Deployed with Batch Transform\n",
      "3. Get the Amazon SageMaker runtime client, which provides the invoke_endpoint  method.\n",
      "runtime_client = boto3.client('runtime.sagemaker')\n",
      "4. Get inferences from the ﬁrst 10 examples in the test dataset by calling invoke_endpoint .\n",
      "with open('test_data', 'r') as f:\n",
      "    \n",
      "    for i in range(0,10):\n",
      "        single_test = f.readline()\n",
      "        response = runtime_client.invoke_endpoint(EndpointName = endpoint_name,\n",
      "                                         ContentType = 'text/csv',\n",
      "                                         Body = single_test)\n",
      "        result = response['Body'].read().decode('ascii')\n",
      "        print('Predicted label is {}.'.format(result))\n",
      "5. To see if the model is making accurate predictions, check the output from this step against the\n",
      "numbers you plotted in the previous step.\n",
      "You have now trained, deployed, and validated your ﬁrst model in Amazon SageMaker.\n",
      "Next Step\n",
      "Step 8: Clean Up  (p. 35)\n",
      "Step 7.2: Validate a Model Deployed with Batch\n",
      "Transform\n",
      "You now have a ﬁle in Amazon S3 that contains inferences that you got by running a batch transform job\n",
      "in Step 6.2: Deploy the Model with Batch Transform (p. 28). To validate the model, check a subset of\n",
      "the inferences from the ﬁle to see whether they match the actual numbers from the test dataset.\n",
      "To validate the batch transform inferences\n",
      "1. Download the test data from Amazon S3.\n",
      "s3 = boto3.resource('s3')\n",
      "33', metadata={'source': 'Lab03/raw-pdfs/AmazonSageMakerDeveloperGuide.pdf', 'page': 40})"
     ]
    }
   ],
   "source": [
    "documents_custom[121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d6789c4-9b7c-4fe3-93e3-2533513ea404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47d41678-45aa-4731-9429-a5a00c1e5cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of docs after split 8841"
     ]
    }
   ],
   "source": [
    "docs = global_text_splitter.split_documents(documents_custom)\n",
    "print(f\"Total number of docs after split {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95fb2184-e098-4582-90ec-ddc0fea5916a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon SageMaker Developer Guide\n",
      "Amazon SageMaker Service\n",
      "TransformInput\n",
      "Service: Amazon SageMaker Service\n",
      "Describes the input source of a transform job and the way the transform job consumes it.\n",
      "Contents\n",
      "CompressionType\n",
      "If your transform data is compressed, specify the compression type. Amazon SageMaker\n",
      "automatically decompresses the data for the transform job accordingly. The default value is None .\n",
      "Type: String\n",
      "Valid Values: None | Gzip\n",
      "Required: No\n",
      "ContentType\n",
      "The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses the\n",
      "MIME type with each http call to transfer data to the transform job.\n",
      "Type: String\n",
      "Length Constraints: Maximum length of 256.\n",
      "Pattern: .*\n",
      "Required: No\n",
      "DataSource\n",
      "Describes the location of the channel data, which is, the S3 location of the input data that the model\n",
      "can consume.\n",
      "Type: TransformDataSource (p. 1023 ) object\n",
      "Required: Yes\n",
      "SplitType"
     ]
    }
   ],
   "source": [
    "print(docs[2695].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e40185c-15e3-4cbd-9d82-30af418d1378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_embeddings(input_text_sample):\n",
    "    \n",
    "    assert isinstance(input_text_sample, str), f\"Input must be a single string but found \" \n",
    "    \n",
    "    lambda_client = boto3.client('lambda', region_name='us-east-1') \n",
    "\n",
    "    # Prepare the data to send to the Lambda function\n",
    "    data = {\n",
    "        \"input\": input_text_sample\n",
    "    }\n",
    "\n",
    "    # Invoke the Lambda function\n",
    "    response = lambda_client.invoke(\n",
    "        FunctionName=\"invoke-inference\",\n",
    "        InvocationType=\"RequestResponse\",\n",
    "        Payload=json.dumps(data)\n",
    "    )\n",
    "\n",
    "    # Decode and load the response payload\n",
    "    response_payload = json.loads(response['Payload'].read().decode(\"utf-8\"))\n",
    "\n",
    "    # Extract status and embeddings from the response\n",
    "    status_code, embeddings = int(response_payload['statusCode']), json.loads(response_payload['body'])\n",
    "\n",
    "    return status_code, embeddings\n",
    "    \n",
    "class EmbeddingsGenerator:\n",
    "    \n",
    "    @staticmethod\n",
    "    def embed_documents(input_text, normalize=True):\n",
    "        \"\"\"\n",
    "        Generate embeddings for the provided text, invoking a Lambda function.\n",
    "        \"\"\"\n",
    "        assert isinstance(input_text, list), \"Input type must me list to embed_documents function\"\n",
    "        \n",
    "        input_text_rdd = spark.sparkContext.parallelize(input_text)\n",
    "        \n",
    "        embeddings_generated = input_text_rdd.map(generate_embeddings).collect()\n",
    "        \n",
    "        embedding_response = []\n",
    "        for s_code, embeddings in embeddings_generated:\n",
    "            if s_code == 200:\n",
    "                embedding_response.append(embeddings)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        return embedding_response\n",
    "    \n",
    "    @staticmethod\n",
    "    def embed_query(input_text):\n",
    "        status_code, embedding = generate_embeddings(input_text)\n",
    "        if status_code == 200:\n",
    "            return embedding\n",
    "        else: \n",
    "            None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3d81eb0d-e91a-450c-b841-371f1297a28c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status 200, Embedding size of the document ---> 384"
     ]
    }
   ],
   "source": [
    "response_code, sample_sentence_embedding = generate_embeddings(docs[1001].page_content)\n",
    "print(f\"Status {response_code}, Embedding size of the document --->\", len(sample_sentence_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d9b0e5b-9705-4a18-8368-15618ea4146c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "INDEX_NAME_OSE = \"amz-data-dev-guides-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0aac1b62-9fbe-4c17-a3c7-c0d23354176a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'INDEX_NAME_OSE' as 'INDEX_NAME_OSE' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i INDEX_NAME_OSE -t str -n INDEX_NAME_OSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "203689c0-015b-4700-8d56-3083e97d4969",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time for ingestion: 929.39 secs"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "docsearch = OpenSearchVectorSearch.from_documents(\n",
    "    docs, \n",
    "    EmbeddingsGenerator, \n",
    "    opensearch_url=\"https://search-docsearchosdb-47fjsdj2ewsjpx4b34qz762kxy.us-east-1.es.amazonaws.com\",\n",
    "    bulk_size=len(docs),\n",
    "    http_auth=(\"admin\", \"Admin123-\"),\n",
    "    index_name=INDEX_NAME_OSE,\n",
    "    engine=\"faiss\"\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Total Time for ingestion: {round(end - start, 2)} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f47ef10c-a50e-4c01-b647-befb7e1f4c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What is a Training Job?\"\n",
    "sample_responses = docsearch.similarity_search(\n",
    "    query, \n",
    "    k=5, \n",
    "    space_type=\"cosineSimilarity\", \n",
    "    search_type=\"painless_scripting\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96fecfc5-f0cd-4064-82c8-aff9f6b3013c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'jobs. To view a summary of the status of all of the training jobs that the hyperparameter tuning job\\nlaunched, see Training job status counter.\\n300'"
     ]
    }
   ],
   "source": [
    "sample_responses[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d5adaca-a9eb-486f-9f08-84cf2f0f9bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "!python3 -m pip install -q opensearch-py==2.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ef95bafd-e975-436a-9622-1aa1d36b9fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    def __init__(self):\n",
    "        self.lambda_client = boto3.client('lambda', region_name='us-east-1')\n",
    "    \n",
    "    def embed_query(self, input_text_sample):\n",
    "        \"\"\"Generate embeddings for the input text.\"\"\"\n",
    "        assert isinstance(input_text_sample, str), \"Input must be a single string.\"\n",
    "        \n",
    "        # Prepare the data to send to the Lambda function.\n",
    "        data = {\"input\": input_text_sample}\n",
    "\n",
    "        # Invoke the Lambda function.\n",
    "        response = self.lambda_client.invoke(\n",
    "            FunctionName=\"invoke-inference\",\n",
    "            InvocationType=\"RequestResponse\",\n",
    "            Payload=json.dumps(data)\n",
    "        )\n",
    "\n",
    "        # Decode and load the response payload.\n",
    "        response_payload = json.loads(response['Payload'].read().decode(\"utf-8\"))\n",
    "\n",
    "        # Extract status and embeddings from the response.\n",
    "        status_code, embeddings = int(response_payload['statusCode']), json.loads(response_payload['body'])\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "embedding_generator = EmbeddingGenerator()\n",
    "\n",
    "docsearch = OpenSearchVectorSearch(\n",
    "    index_name=INDEX_NAME_OSE,\n",
    "    embedding_function=embedding_generator,\n",
    "    opensearch_url=\"https://search-docsearchosdb-47fjsdj2ewsjpx4b34qz762kxy.us-east-1.es.amazonaws.com\",\n",
    "    http_auth=(\"admin\", \"Admin123-\"),\n",
    "    engine=\"faiss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3526c1b2-af46-410e-922a-f1687af1acd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "import re\n",
    "import json\n",
    "from typing import Dict\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.llms import SagemakerEndpoint\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    \n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        \n",
    "        pattern = r\"(QUESTION:\\n)(.*?)(\\n\\n)\"\n",
    "        \n",
    "        match = re.search(pattern, prompt, re.DOTALL)\n",
    "        \n",
    "        # question_block = match.group(0)\n",
    "        query_only = match.group(2)\n",
    "        \n",
    "        modified_prompt = re.sub(pattern, '', prompt, flags=re.DOTALL)\n",
    "        \n",
    "        body = {\n",
    "            \"inputs\": [\n",
    "                [\n",
    "                     {\n",
    "                         \"role\": \"system\", \n",
    "                         \"content\": modified_prompt\n",
    "                     },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": query_only\n",
    "                    },\n",
    "                ]   \n",
    "            ], \n",
    "            \"parameters\": model_kwargs\n",
    "        }\n",
    "        input_str = json.dumps(body)\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        system_response = response_json[0]['generation']['content']\n",
    "        return system_response.strip()\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "\n",
    "llm_sm_ep = SagemakerEndpoint(\n",
    "    endpoint_name=\"jumpstart-dft-meta-textgeneration-llama-2-7b-f\", \n",
    "    region_name=\"us-east-1\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512, \n",
    "        \"top_p\": 1.0, \n",
    "        \"temperature\": 0.1, \n",
    "        \"return_full_text\": False\n",
    "    },\n",
    "    content_handler=content_handler,\n",
    "    endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7bf50f9e-f64d-4bf6-9bd4-d8c924da06ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the following QUESTION based on the CONTEXT\n",
    "given. If you do not know the answer and the CONTEXT doesn't\n",
    "contain the answer truthfully say \"I don't know\".\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template, \n",
    "    input_variables=['context', 'question']\n",
    ")\n",
    "\n",
    "llm_qa_smep_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_sm_ep,\n",
    "    chain_type='stuff',\n",
    "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 10, \"space_type\": \"cosineSimilarity\", \"space_type\": \"painless_scripting\"}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")\n",
    "\n",
    "\n",
    "def pretty_print(chain_op):\n",
    "    question = chain_op['query']\n",
    "    \n",
    "    response = chain_op['result']\n",
    "    \n",
    "    sources = \"\\n\".join([f\"-{src.metadata['source'].split('/')[-1]} (page: {src.metadata['page']})\" for src in chain_op['source_documents']])\n",
    "    \n",
    "    stdout = f\"\"\"Question:\\n> {question}\\n\\n================\\nSystem:\\n> {response}\\n\\n================\\nSources:\\n{sources}\n",
    "    \"\"\"\n",
    "    print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76c24205-1c2b-49f3-a36d-af213ee12a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "> What is a SageMaker Training job and how do you run it?\n",
      "\n",
      "================\n",
      "System:\n",
      "> Based on the provided context, a SageMaker training job is a process of using an algorithm to run a training job in Amazon SageMaker. To run a training job, you can use the Amazon SageMaker console, the low-level Amazon SageMaker API, or the Amazon SageMaker Python SDK.\n",
      "\n",
      "Here are the general steps to run a training job:\n",
      "\n",
      "1. Choose an algorithm that you want to use for training.\n",
      "2. Provide information about the training job, such as the job name, IAM role, and S3 bucket where the output will be stored.\n",
      "3. Launch the training job using the chosen algorithm.\n",
      "\n",
      "The context provides more detailed information on how to run a training job using the Amazon SageMaker console, the low-level Amazon SageMaker API, or the Amazon SageMaker Python SDK.\n",
      "\n",
      "================\n",
      "Sources:\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 756)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 428)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 427)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 8)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 287)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 373)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 464)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 12)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 306)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 288)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"What is a SageMaker Training job and how do you run it?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3dc9db4-5897-4227-a38b-b427eae71e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "> What types of instances are supported for Training Job?\n",
      "\n",
      "================\n",
      "System:\n",
      "> Based on the context provided, the following instance types are supported for training jobs:\n",
      "\n",
      "1. P2/P3 EC2 instances in single machine configurations.\n",
      "2. ML instances (such as ml.p2.xlarge, ml.p2.8xlarge, ml.p2.16xlarge, ml.p3.2xlarge, ml.p3.8xlarge, and ml.p3.16xlarge) for both training and inference.\n",
      "\n",
      "Note that the context does not mention any specific instance types for distributed training, so it is possible that only single machine configurations are supported for distributed training.\n",
      "\n",
      "================\n",
      "Sources:\n",
      "-EMRManagementGuide.pdf (page: 13)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 125)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 119)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 676)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 210)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 286)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 420)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 213)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 756)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 245)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"What types of instances are supported for Training Job?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92c62707-02ec-42c3-9a8b-ade8f45670e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "> How to install packages on EC2 instances using Command line?\n",
      "\n",
      "================\n",
      "System:\n",
      "> Based on the provided context, you can install packages on EC2 instances using the command line by following these steps:\n",
      "\n",
      "1. Install the source code for the package you want to install using the `get_reference_source` command. For example, to download the source code for the `htop` package, you can run `get_reference_source -p htop`.\n",
      "2. Install the package using the `pip` or `conda` command. For example, to install the `htop` package using `pip`, you can run `pip install htop`.\n",
      "3. If you want to install multiple packages at once, you can use the `yum grouppinstall` command to install multiple packages and all their dependencies at once. For example, to install the `php` package and its dependencies, you can run `yum grouppinstall \"Performance Tools\"`.\n",
      "\n",
      "Note: The `yum` command is used to install RPM packages, while `pip` and `conda` are used to install Python packages.\n",
      "\n",
      "Also, you can use the `aws ec2 run-instances` command to launch an instance from a custom AMI, and then use the command line to install packages on the instance.\n",
      "\n",
      "It's important to note that the commands and file locations may be similar for other distributions, but the specific commands and syntax may vary. For more information about installing packages on other distributions, see their specific documentation.\n",
      "\n",
      "================\n",
      "Sources:\n",
      "-EC2DeveloperGuide.pdf (page: 338)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 48)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 49)\n",
      "-EC2DeveloperGuide.pdf (page: 337)\n",
      "-EC2DeveloperGuide.pdf (page: 51)\n",
      "-EC2DeveloperGuide.pdf (page: 104)\n",
      "-EMRManagementGuide.pdf (page: 227)\n",
      "-EC2DeveloperGuide.pdf (page: 137)\n",
      "-EC2DeveloperGuide.pdf (page: 60)\n",
      "-EC2DeveloperGuide.pdf (page: 47)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How to install packages on EC2 instances using Command line?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "35d59090-4017-4f27-a5a3-9e72f84a049d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "> How to Create a Training Job using Boto3 SDK?\n",
      "\n",
      "================\n",
      "System:\n",
      "> Based on the provided context, the answer to your question is:\n",
      "\n",
      "I don't know.\n",
      "\n",
      "The context does not provide enough information to answer your question about how to create a training job using the Boto3 SDK. The context only provides information on how to create a training job using the Amazon SageMaker Python SDK or the AWS SDK for Python (Boto 3). It does not provide any information on how to create a training job using the Boto3 SDK.\n",
      "\n",
      "To create a training job using the Boto3 SDK, you will need to consult the AWS SDK for Python (Boto 3) documentation or seek additional information from a reliable source.\n",
      "\n",
      "================\n",
      "Sources:\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 31)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 303)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 2)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 32)\n",
      "-S3DeveloperGuide.pdf (page: 508)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 854)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 1007)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 292)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 36)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 428)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How to Create a Training Job using Boto3 SDK?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5c615cd-1245-4cc0-9391-164102395efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "> How can I deploy a model to SageMaker Hosting service?\n",
      "\n",
      "================\n",
      "System:\n",
      "> To deploy a model to Amazon SageMaker hosting services, you can follow these steps:\n",
      "\n",
      "1. Create a model in Amazon SageMaker by providing the location of the S3 bucket that contains the model artifacts and the registry path of the image that contains the inference code.\n",
      "2. Create an endpoint configuration for an HTTPS endpoint by specifying the name of one or more models in production variants and the ML compute instances that you want Amazon SageMaker to launch to host each production variant.\n",
      "3. Create an endpoint by sending a CreateEndpoint request to Amazon SageMaker, which launches the ML compute instances and deploys the model. Applications can then send requests for inference to this endpoint.\n",
      "\n",
      "Note that you can also use the AWS SDK for Python (Boto 3) to deploy a model to Amazon SageMaker hosting services. The process is similar to the above steps, but you will need to use the CreateModel, CreateEndpointConﬁg, and CreateEndpoint APIs provided by the SDK.\n",
      "\n",
      "================\n",
      "Sources:\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 433)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 33)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 16)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 655)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 15)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 34)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 642)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 37)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 636)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 434)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How can I deploy a model to SageMaker Hosting service?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3cb8cec4-7304-4c5f-93c7-1d77b041c31d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "> How do I validate a model using boto3 sdk and visualize results using matplotlib library?\n",
      "\n",
      "================\n",
      "System:\n",
      "> To validate a model using the AWS SDK for Python (Boto 3) and visualize the results using the matplotlib library, you can follow these steps:\n",
      "\n",
      "1. Download the test data from Amazon S3 using the `boto3.resource('s3')` object.\n",
      "2. Use the `boto3.client('runtime.sagemaker')` object to invoke the endpoint and get the inferences for the first 10 examples in the test dataset.\n",
      "3. Read the inferences from the response object and plot them using the matplotlib library.\n",
      "4. Repeat steps 2 and 3 to get the inferences for the remaining examples in the test dataset.\n",
      "5. Compare the predicted labels with the actual labels in the test dataset to validate the model.\n",
      "\n",
      "Here is an example code snippet that demonstrates how to validate a model using the AWS SDK for Python (Boto 3) and visualize the results using the matplotlib library:\n",
      "```python\n",
      "import boto3\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Download the test data from Amazon S3\n",
      "s3 = boto3.resource('s3')\n",
      "test_key = \"your-test-data-key\"\n",
      "s3.Bucket(bucket).download_file(test_key, 'test_data')\n",
      "\n",
      "# Invoke the endpoint and get the inferences for the first 10 examples in the test dataset\n",
      "endpoint_name = \"your-endpoint-name\"\n",
      "content_type = \"text/csv\"\n",
      "body = open('test_data', 'r').read()\n",
      "response = boto3.client('runtime.sagemaker').invoke_endpoint(EndpointName=endpoint_name, ContentType=content_type, Body=body)\n",
      "inferences = response['Body'].read().decode('ascii')\n",
      "\n",
      "# Plot the inferences\n",
      "plt.plot(inferences.splitlines())\n",
      "plt.xlabel('Predicted Label')\n",
      "plt.ylabel('Actual Label')\n",
      "plt.show()\n",
      "\n",
      "# Repeat step 3 to get the inferences for the remaining examples in the test dataset\n",
      "for i in range(10, len(inferences.splitlines())):\n",
      "    inference = inferences.splitlines()[i]\n",
      "    plt.plot(inference.split(','))\n",
      "    plt.xlabel('Predicted Label')\n",
      "\n",
      "================\n",
      "Sources:\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 39)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 40)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 38)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 444)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 303)\n",
      "-S3DeveloperGuide.pdf (page: 508)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 40)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 41)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 292)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 37)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How do I validate a model using boto3 sdk and visualize results using matplotlib library?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "651df026-405c-4a4a-9530-8c252a703a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "> How can I use the console to add a git repository to my SageMaker account?\n",
      "\n",
      "================\n",
      "System:\n",
      "> To add a Git repository to your Amazon SageMaker account using the console, follow these steps:\n",
      "\n",
      "1. Open the Amazon SageMaker console at <https://console.aws.amazon.com/sagemaker/>.\n",
      "2. Choose \"Git repositories\" from the left-hand menu.\n",
      "3. Click on \"Add repository\" in the top right corner of the page.\n",
      "4. Select \"AWS CodeCommit\" as the repository type.\n",
      "5. Enter a name for the repository in the \"Repository name\" field. The name must be 1-63 characters long and can contain only letters (a-z), numbers (0-9), or dashes (-).\n",
      "6. Choose \"Use existing repository\" or \"Create a new repository\" depending on whether you want to use an existing CodeCommit repository or create a new one.\n",
      "7. If you choose \"Use existing repository,\" select the repository from the list. If you choose \"Create a new repository,\" enter a name for the repository and choose \"Add repository.\"\n",
      "8. If you want to associate the repository with a notebook instance, choose \"Associate a public Git repository\" and enter the URL of the repository.\n",
      "9. Choose \"Create repository\" to add the Git repository to your Amazon SageMaker account.\n",
      "\n",
      "Note: If you want to use a private Git repository, you will need to provide credentials to access the repository. You can do this by choosing \"Git credentials\" and entering the necessary information.\n",
      "\n",
      "================\n",
      "Sources:\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 54)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 54)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 57)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 55)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 57)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 55)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 59)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 60)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 634)\n",
      "-AmazonSageMakerDeveloperGuide.pdf (page: 56)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "pretty_print(llm_qa_smep_chain(\"How can I use the console to add a git repository to my SageMaker account?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1face8fd-d580-4907-bb2f-425d5b8a4486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.c5.2xlarge",
  "kernelspec": {
   "display_name": "SparkMagic PySpark (SparkAnalytics 2.0)",
   "language": "python",
   "name": "conda-env-sm_sparkmagic-pysparkkernel__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-sparkanalytics-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
