{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2653ca-b172-42c7-bfe2-af170798d53c",
   "metadata": {},
   "source": [
    "## Lab 0: Warm Up: Deploy Llama 2 Models on ml.inf2.24xlarge for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb4aa4-05ca-4499-b960-8251a17b304b",
   "metadata": {},
   "source": [
    "In this lab, we'll walk you throught the process of deploying an Open Source Llama2 Model to a SageMaker endpoint for inference. We're going to leverage 1 `ml.inf2.24xlarge` machine for this and subsequent labs. In practice, you can deploy a SageMaker model behind a single load balanced endpoint with auto-scaling policies defined - allowing your LLM SaaS endpoint to scale with input demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c685295-0b10-4db6-9335-acf161fdb83c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #FFDDDD; border-left: 5px solid red; padding: 10px; color: black;\">\n",
    "    <strong>Kernel:</strong> Python 3 (ipykernel)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc91f4-44df-4e3b-be00-c83dc6268f8b",
   "metadata": {},
   "source": [
    "### _Temporary Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1198a6a1-9c9d-4a8a-ba6c-166d8c6b0281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  models.zip\n",
      "   creating: models/\n",
      "   creating: models/sagemaker/\n",
      "   creating: models/sagemaker/2017-07-24/\n",
      "  inflating: models/sagemaker/2017-07-24/service-2.sdk-extras.json  \n",
      "/home/sagemaker-user/.aws:\n",
      "models\n",
      "sagemaker\n",
      "\n",
      "/home/sagemaker-user/.aws/models:\n",
      "sagemaker\n",
      "\n",
      "/home/sagemaker-user/.aws/models/sagemaker:\n",
      "2017-07-24\n",
      "\n",
      "/home/sagemaker-user/.aws/models/sagemaker/2017-07-24:\n",
      "service-2.sdk-extras.json\n",
      "\n",
      "/home/sagemaker-user/.aws/sagemaker:\n",
      "2017-07-24\n",
      "\n",
      "/home/sagemaker-user/.aws/sagemaker/2017-07-24:\n",
      "service-2.sdk-extras.json\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "unzip models.zip\n",
    "\n",
    "mv models ~/.aws/\n",
    "\n",
    "ls -R ~/.aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb76f18-4f3d-4f5f-a320-fec331bd6b26",
   "metadata": {},
   "source": [
    "## Llama 2 License Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122d5f10-7b51-47c8-8aff-0eba1bce0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, Layout, HTML\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8e060b-8795-49ab-877b-e9676c9d44b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a0b14f5ab04a6c9bfba67c9a2924c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Accept Llama 2 EULA?', index=1, layout=Layout(width='auto'), options=('True', 'False'), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LLAMA2_EULA = False\n",
    "\n",
    "# Creating the dropdown\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=['True', 'False'],\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=Layout(width='auto'),  # Adjusts the width of the dropdown to fit the content\n",
    "    value='False',\n",
    "    description='Accept Llama 2 EULA?',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Function to be called on value change\n",
    "def on_dropdown_change(change):\n",
    "    global LLAMA2_EULA\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        LLAMA2_EULA = eval(change['new'])\n",
    "        print(f\"User set EULA to {LLAMA2_EULA}\")\n",
    "\n",
    "# Observing the dropdown for changes\n",
    "dropdown.observe(on_dropdown_change, names='value')\n",
    "\n",
    "# Display the HTML link and the dropdown\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c836900-4323-4b11-bf59-09e8ef8f9ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User set EULA to --> True\n"
     ]
    }
   ],
   "source": [
    "print(f\"User set EULA to --> {LLAMA2_EULA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9516c95-070d-42d7-99a5-893a7d91371c",
   "metadata": {},
   "source": [
    "## Setup Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95f6a1-9d4e-47dc-8225-1edf09378023",
   "metadata": {},
   "source": [
    "Let's install some packages that would be required for this and some sub-sequent labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51be30-c371-4923-bb3f-13090fd923f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install ./sagemaker-2.297.1.dev0-py2.py3-none-any.whl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663a7807-63dc-47bb-9b76-a1971ce3cead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6888ee73-548e-4681-9c5a-1f76287f6967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "\n",
      "SageMaker python SDK version ---> 2.297.1.dev0 | Region ---> us-west-2 | Role ---> arn:aws:iam::914153712152:role/workshop-studio-v2-cfn-OSE-EMR-SageMakerExecutionRole\n"
     ]
    }
   ],
   "source": [
    "REGION = \"us-west-2\"\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3.Session(region_name=REGION))\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=REGION)\n",
    "role = \"arn:aws:iam::914153712152:role/workshop-studio-v2-cfn-OSE-EMR-SageMakerExecutionRole\" #sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"\\nSageMaker python SDK version ---> {sagemaker.__version__} | Region ---> {sagemaker_session.boto_session.region_name} | Role ---> {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55be0cee-1048-40e4-860c-97474dd86af0",
   "metadata": {},
   "source": [
    "### Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "345a1094-56a0-447f-810e-3683a1a9bb0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_MODEL_NAME = \"llama2\"\n",
    "_MODEL_SIZE = \"13b\"\n",
    "\n",
    "MODEL_NAME = f\"meta-{_MODEL_NAME}-{_MODEL_SIZE}-neuron-chat-tg-model\"\n",
    "ENDPOINT_NAME = f\"meta-{_MODEL_NAME}-{_MODEL_SIZE}-neuron-chat-tg-ep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc116c2f-8bc1-48d6-ae13-bda81f1393c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('meta-llama2-13b-neuron-chat-tg-model', 'meta-llama2-13b-neuron-chat-tg-ep')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME, ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c6b16-551c-41cd-972c-17af3b87de32",
   "metadata": {},
   "source": [
    "## Let's Deploy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3146c498-2a52-4d45-b027-b26a2374fe18",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Llama 2 Model](https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_vector_art_cybernetic_llama_wearing_sunglasses_synthwav_d3f82260-2c47-4abd-9599-b91751711f5b.png?fit=750%2C420&strip=all)\n",
    "\n",
    "*Image Credits: https://venturebeat.com/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bd23f-064b-45b6-beec-85e5aee7aa87",
   "metadata": {},
   "source": [
    "### Model and Instance Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f39ced8-79fa-46a4-9dc4-4c49747b1cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JUMPSTART_SRC_MODEL_NAME = \"meta-textgenerationneuron-llama-2-13b-f\"\n",
    "INSTANCE_TYPE = \"ml.inf2.24xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff08cf5c-516f-4f11-99ab-a39267b9dc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temporary workaround\n",
    "os.environ.update({\n",
    "    \"AWS_JUMPSTART_CONTENT_BUCKET_OVERRIDE\": \"jumpstart-cache-alpha-us-west-2\",\n",
    "    \"AWS_JUMPSTART_GATED_CONTENT_BUCKET_OVERRIDE\": \"jumpstart-private-cache-prod-us-west-2\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a091c2-a555-4400-831a-466131bcbd1b",
   "metadata": {},
   "source": [
    "### Deploy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1f78a-5a4a-4cb3-9cef-288864837d28",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://cdn.jim-nielsen.com/ios/1024/lets-go-rocket-2018-10-15.png\" width=\"512\" height=\"512\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481388a6-8a27-4b3c-b7b5-2a2148542fa6",
   "metadata": {},
   "source": [
    "We're going to deploy our Llama2 model on Amazon Silicon Inferentia `Inf2`. Inferentia instances are purpose built for deep learning (DL) inference. They deliver high performance at the lowest cost in Amazon EC2 for generative artificial intelligence (AI) models, including large language models (LLMs) and vision transformers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87d499d-2d4f-4fd7-81c4-292b4d79723e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e219c0d-c7f6-450f-ba4f-c7e78158b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgenerationneuron-llama-2-13b-f' with wildcard version identifier '*'. You can pin to version '1.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "Using model 'meta-textgenerationneuron-llama-2-13b-f' with wildcard version identifier '*'. You can pin to version '1.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    }
   ],
   "source": [
    "llama2_13b_model = JumpStartModel(\n",
    "    model_id=JUMPSTART_SRC_MODEL_NAME,\n",
    "    env={\n",
    "        \"OPTION_DTYPE\": \"fp16\",\n",
    "        \"OPTION_N_POSITIONS\": \"2048\",\n",
    "        \"OPTION_TENSOR_PARALLEL_DEGREE\": \"12\"\n",
    "    },\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22e4fc74-5076-4ea3-8242-57a9f8436e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your model is not compiled. Please compile your model before using Inferentia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== SageMaker Deployment =====\n",
      "\n",
      "Preparing to deploy the model...\n",
      "------------------------------------------------------!\n",
      "===== Deployment Complete =====\n",
      "CPU times: user 429 ms, sys: 32 ms, total: 461 ms\n",
      "Wall time: 27min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"===== SageMaker Deployment =====\")\n",
    "\n",
    "print(\"\\nPreparing to deploy the model...\")\n",
    "llama2_13b_model.deploy(\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    accept_eula=LLAMA2_EULA\n",
    ")\n",
    "print(\"\\n===== Deployment Complete =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613d786-10b5-4342-a83a-779f8363eab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
