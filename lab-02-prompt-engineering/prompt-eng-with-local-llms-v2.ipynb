{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96aba234-390a-4504-8b26-dce11f7f7d37",
   "metadata": {},
   "source": [
    "## Lab 2: Prompt Engineering with LLMs on SageMaker Studio.\n",
    "\n",
    "Prompt engineering is a cool, new way of making language computer programs, also known as language models, work better for all kinds of jobs and studies. This skill helps us get to know what these big computer programs can do well and what they can't.\n",
    "\n",
    "Scientists use prompt engineering to make these language models better at doing a bunch of different things, like answering questions or solving math problems. Programmers use it to create strong and useful ways to interact with these big language models and other tech stuff.\n",
    "\n",
    "But prompt engineering isn't just about making questions or commands for these models. It's a whole set of skills that help us work better with them. We can use these skills to make the language models safer and even add new features, like making them smarter in specific subjects.\n",
    "\n",
    "In this lab, we learn how to:\n",
    "1. use SageMaker to download, provision, and send prompts to a Large Language Model, Llama 2.\n",
    "2. Learn basic and Advamced prompting techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd252a3-7a03-445d-9266-484cc40e2e99",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ This notebook is ran on a Data Science 3.0 kernal on an ml.g5.2xlarge instance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25117dc6-328d-4028-b305-9b12008dc1a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model License information\n",
    "---\n",
    "To perform inference on these models, you need to pass `custom_attributes='accept_eula=true'` as part of header. This means you have read and accept the end-user-license-agreement (EULA) of the model. EULA can be found in model card description or from https://ai.meta.com/resources/models-and-libraries/llama-downloads/. By default, this notebook sets `custom_attributes='accept_eula=false'`, so all inference requests will fail until you explicitly change this custom attribute.\n",
    "\n",
    "Note: Custom_attributes used to pass EULA are key/value pairs. The key and value are separated by `'='` and pairs are separated by `';'`. If the user passes the same key more than once, the last value is kept and passed to the script handler (i.e., in this case, used for conditional logic). For example, if `'accept_eula=false; accept_eula=true'` is passed to the server, then `'accept_eula=true'` is kept and passed to the script handler.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22950f07-fddf-467d-ab17-6361d3461eed",
   "metadata": {},
   "source": [
    "### Downlaod and host Llama2 model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf72a3-643a-4242-9aac-fda824d8991b",
   "metadata": {},
   "source": [
    "We begin by installing and upgrading necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b81186a-0ec5-4bc7-ad1c-fe40fa90a87b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9100675d-a2fa-43b0-871c-9e7fbb508c00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain typing_extensions==4.7.1 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8440867a-0d97-48a4-815e-444557354610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db5be8-87ad-4e9a-ae48-8ab60ec5dfd3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ Restart the kernel after executing the cell above for the first time..\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02100e03-cca8-441e-ac5b-170c928d07db",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy\n",
    "\n",
    "First we will deploy the Llama-2 model as a SageMaker endpoint.\n",
    "\n",
    "[Llama 2](https://ai.meta.com/llama/) is the second generation of Meta's open source Large Language Models (LLMs), trained on 2 trillion tokens. In this notebook we will deploy the 13B size and we will specify a Sagemaker instance type of ml.g5.12xlarge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66edd2a3-c491-4a69-bb33-56d501de31a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id, model_version = \"meta-textgeneration-llama-2-13b-f\", \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d25debd0-22ab-4274-b33a-21eeb7698009",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "pretrained_model = JumpStartModel(model_id=model_id, instance_type=\"ml.g5.12xlarge\")\n",
    "pretrained_predictor = pretrained_model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0582bd65-1d7b-411e-9c3c-604a8bc5571c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_llama2_params(\n",
    "    max_new_tokens=512,\n",
    "    top_p=0.9,\n",
    "    temperature=0.6,\n",
    "):\n",
    "    \"\"\" set Llama2 parameters \"\"\"\n",
    "    llama2_params = {}\n",
    "    \n",
    "    llama2_params['max_new_tokens'] = max_new_tokens\n",
    "    llama2_params['top_p'] = top_p\n",
    "    llama2_params['temperature'] = temperature\n",
    "    return llama2_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "832f9821-bc0a-4839-aafb-4c803624f8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_dialog(payload, response):\n",
    "    dialog_output = []\n",
    "    dialog = payload[\"inputs\"][0]\n",
    "    for msg in dialog:\n",
    "        dialog_output.append(f\"**{msg['role'].capitalize()}**: {msg['content']}\\n\")\n",
    "    dialog_output.append(f\"**{response[0]['generation']['role'].capitalize()}**: {response[0]['generation']['content']}\")\n",
    "    dialog_output.append(\"\\n==================================\\n\")\n",
    "    \n",
    "    display(Markdown('\\n'.join(dialog_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6218f3a-58c6-4b73-b390-21779fb3c865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send_prompt(params, prompt, instruction=\"\"):\n",
    "    \n",
    "    custom_attributes=\"accept_eula=true\"\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": [[\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]],\n",
    "        \"parameters\": params\n",
    "    }\n",
    "    response = pretrained_predictor.predict(payload, custom_attributes=custom_attributes)\n",
    "    print_dialog(payload, response)\n",
    "    return payload, response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ca8d7-3691-431c-98cd-6714a43a0177",
   "metadata": {},
   "source": [
    "## Prompt Engineering Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ba2e2-83fb-4f75-b57e-eb3f9d239ec0",
   "metadata": {},
   "source": [
    "### Basic prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6fbd5da7-1e25-44f3-ac22-a2711f0a6f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**System**: \n",
       "\n",
       "**User**: Why is the sky blue?\n",
       "\n",
       "**Assistant**:  The sky appears blue because of a phenomenon called Rayleigh scattering, which is the scattering of light by small particles in the atmosphere. The particles, such as nitrogen and oxygen molecules, are much smaller than the wavelength of light, so they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is why the sky appears blue during the daytime, as the blue light is scattered in all directions and reaches our eyes from all parts of the sky.\n",
       "\n",
       "In addition to Rayleigh scattering, the sky can also appear blue due to the presence of aerosols and clouds, which can scatter light in a similar way. The blue color of the sky can also be influenced by the time of day, the amount of sunlight, and the presence of other atmospheric factors such as pollution and dust.\n",
       "\n",
       "So, to summarize, the sky appears blue because of the scattering of light by small particles in the atmosphere, and the specific wavelengths of light that are scattered give the sky its blue color.\n",
       "\n",
       "==================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.75 ms, sys: 0 ns, total: 5.75 ms\n",
      "Wall time: 4.27 s\n"
     ]
    }
   ],
   "source": [
    "params = set_llama2_params(temperature=0.1)\n",
    "payload, response = send_prompt(params, prompt=\"Why is the sky blue?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01bd8b2-8444-46ff-a0ae-47f44df7982c",
   "metadata": {},
   "source": [
    "### Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5bd2b305-7270-4894-aa02-6d3e1181405c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**System**: \n",
       "\n",
       "**User**: Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance. \n",
       "\n",
       "Explain the above in one sentence:\n",
       "\n",
       "**Assistant**:  Sure! Here's the explanation in one sentence:\n",
       "\n",
       "Antibiotics are medications that kill or inhibit the growth of bacteria to treat infections, but they are ineffective against viral infections and misuse can lead to antibiotic resistance.\n",
       "\n",
       "==================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = set_llama2_params(temperature=0.7)\n",
    "prompt = \"\"\"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance. \n",
    "\n",
    "Explain the above in one sentence:\"\"\"\n",
    "payload, response = send_prompt(params, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a16671-9bee-4c96-be62-6123276db46a",
   "metadata": {},
   "source": [
    "Exercise: Instruct the model to explain the paragraph in one sentence like \"I am 5\". Do you see any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899e56b-023a-40c4-9af3-b864b38bfe1c",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d0d00-3fe6-45c6-934d-30c9752d4b86",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052b3b76-3a16-44a8-b185-829e7f7fabdd",
   "metadata": {},
   "source": [
    "### Role Playing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef73a5-f0d9-4f02-98e3-eb8e63cc3b6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Code Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d84d67-278e-4d7f-8125-9c34537b9850",
   "metadata": {},
   "source": [
    "### Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bd521-5eb0-4c44-b218-11aa057f7af3",
   "metadata": {},
   "source": [
    "## Advanced Prompting Techniques\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d13399-340a-4120-9e73-81de1f5e0cb7",
   "metadata": {},
   "source": [
    "### Few-shot prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e840c09-62cc-4c67-972a-b6c391d608aa",
   "metadata": {},
   "source": [
    "### Chain-of-Thought (CoT) Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cca6b1-1a66-4fe5-b5cc-c37619ef652d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812f0d5-7cad-4ce2-ac1f-c9b52ed2000d",
   "metadata": {},
   "source": [
    "### Zero-shot CoT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b41f9e-5602-4e37-bcf9-9c502da2ab36",
   "metadata": {},
   "source": [
    "## (Optional) Advanced Prompting Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec143e6a-2f39-46c8-81f0-98439e896722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940bdf2e-eebe-4b0e-b9d3-eb1dbfc66039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets make the model deterministic\n",
    "generation_config = model.generation_config\n",
    "\n",
    "# set generator configs\n",
    "generation_config.temperature = 0.1\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.max_new_tokens = 256\n",
    "generation_config.use_cache = False\n",
    "generation_config.top_p=0.95\n",
    "# generation_config.top_k=10\n",
    "# generation_config.do_sample=False\n",
    "generation_config.repetition_penalty = 1.2\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe456286-51c3-46b1-b57e-7c26e05dcacd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    task=\"text-generation\",\n",
    "    generation_config=generation_config\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(\n",
    "    pipeline=generation_pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2bacb-9acc-42c4-871c-ed2d8168ee9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "### Instruction\n",
    "Classify the text into neutral, negative or positive\n",
    "\n",
    "### Context\n",
    "Text: {query}\n",
    "\n",
    "### Answer\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\n",
    "        \"query\"\n",
    "    ],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f7abe-93e5-4ecf-9a03-5970e79858de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=local_llm,\n",
    "    prompt=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253638c-053d-496b-877f-71d2f25eee27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = llm_chain.run(\n",
    "    query=\"I am ok talking to John\"\n",
    ")\n",
    "print(response.strip().upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38167a87-82fd-4f96-ae92-8e1ba3c4bc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = llm_chain.run(\n",
    "    query=\"I think the sandwich was fantastic!\"\n",
    ")\n",
    "print(response.strip().upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c9625-ef77-4f98-8cc4-04e42cc5f595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = llm_chain.run(\n",
    "    query=\"I think the sandwich was awful!\"\n",
    ")\n",
    "print(response.strip().upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e78ca-ca7b-495c-a5e2-1cfe412ef6c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346efaf-94eb-4470-8062-0b0b748b3110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets make the model's responses more clever\n",
    "generation_config = model.generation_config\n",
    "\n",
    "# set generator configs\n",
    "generation_config.temperature = 1.2\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.max_new_tokens = 256\n",
    "generation_config.use_cache = False\n",
    "generation_config.top_p=0.95\n",
    "# generation_config.top_k=10\n",
    "# generation_config.do_sample=False\n",
    "generation_config.repetition_penalty = 1.2\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7973ff9-ed82-483d-954e-87996f47e7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    task=\"text-generation\",\n",
    "    generation_config=generation_config\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(\n",
    "    pipeline=generation_pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b7d4d-4e75-4452-a2a3-712f955c5bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "### Instruction\n",
    "The following are exerpts from conversations with an AI assistant. The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions.\n",
    "\n",
    "### Context\n",
    "Here are some examples: \n",
    "\n",
    "User: How are you?\n",
    "AI: I can't complain but sometimes I still do.\n",
    "\n",
    "User: What time is it?\n",
    "AI: It's time to get a watch.\n",
    "\n",
    "### Answer\n",
    "User: {query}\n",
    "AI:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\n",
    "        \"query\"\n",
    "    ],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692b4b0-96ca-41b4-b091-224a93600d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=local_llm,\n",
    "    prompt=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8108b110-8389-4505-965d-30c8dfc93245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = llm_chain.run(\n",
    "    query=\"What is the meaning of life?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159de9a-14b0-404a-9a1e-ed4a867ec2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f81b04-2ab8-474b-8cd1-bea2e431345c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LangChain based FewShot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf06fe-d24f-465a-a645-f7839811dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f8bcc-921a-434a-b8ac-4a0ed2eeb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"answer\": \"It's time to get a watch.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85f49f-06cc-446b-90ab-6dc64900c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9dbdf-4809-4691-bbfe-4c0832757ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad033dc3-ee2f-45d8-9f09-cc1356ee4637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"\n",
    "The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97de13-f808-4bc8-b638-e0e64b2a2980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bc893-6732-4c5f-86c3-b42033402e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the meaning of life?\"\n",
    "\n",
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b7076-7914-4862-bddc-48c6c427aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=local_llm,\n",
    "    prompt=few_shot_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ec8dd-0e06-447f-b5d1-b0b433405963",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_chain.run(\n",
    "    query=\"What is the meaning of life?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0dd27-0286-4161-9e52-7f44e6a716a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a1ebde-f588-4690-938c-a6c56cd726b0",
   "metadata": {},
   "source": [
    "### Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ea12e-c6da-477e-9f05-3cec0a6c3b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets make the model's responses more clever\n",
    "generation_config = model.generation_config\n",
    "\n",
    "# set generator configs\n",
    "generation_config.temperature = 0.1\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.max_new_tokens = 128\n",
    "generation_config.use_cache = False\n",
    "generation_config.top_p=0.95\n",
    "generation_config.top_k=25\n",
    "generation_config.do_sample=True\n",
    "generation_config.repetition_penalty = 1.2\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011f679-f25f-4e13-bb9f-91d4661a92a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    task=\"text-generation\",\n",
    "    generation_config=generation_config\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(\n",
    "    pipeline=generation_pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5727c954-0277-4db1-977a-e1f30b3a8f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "### Instruction\n",
    "As a seasoned film connoisseur, I need your advice to expand my movie collection.\n",
    "Can you recommend a film that shares similarities with my favourite movies listed below and select the appropriate option with reference to the question.\n",
    "\n",
    "### Context\n",
    "\n",
    "Human: Find a movie similar to Star Wars Episode IV - A New Hope, Indiana Jones and the Last Crusade, Star Wars Episode V - The Empire Strikes Back, The Big Lebowski:\n",
    "Options:\n",
    "(A) Tetsuo\n",
    "(B) the Ironman\n",
    "(C) The Princess Bride\n",
    "(D) The Barkley Marathons The Race That Eats Its Young\n",
    "(E) Bug\n",
    "\n",
    "Assistant:\n",
    "Let's think step by step.\n",
    "- Star Wars Episode IV - A New Hope (action, adventure, fantasy; 1977)\n",
    "- Indiana Jones and the Last Crusade (action, adventure; 1989)\n",
    "- Star Wars Episode V - The Empire Strikes Back (action, adventure, fantasy; 1980)\n",
    "- The Big Lebowski (action, drama, comedy; 1998)\n",
    "These are all famous classic American movies produced before 2000. Amongst all the options, the only movie similar to these ones seems to be The Princess Bride (1987). So the answer is (C).\n",
    "\n",
    "Human: Find a movie similar to Twister, The Silence of the Lambs, Independence Day, Braveheart:\n",
    "Options:\n",
    "(A) They Shoot Horses\n",
    "(B) Don't They\n",
    "(C) Forrest Gump\n",
    "(D) The Salton Sea\n",
    "(E) Extreme Days\n",
    "\n",
    "Assistant:\n",
    "Let's think step by step.\n",
    "- Twister (action, adventure, thriller; 1996)\n",
    "- The Silence of the Lambs (crime, drama, thriller; 1991)\n",
    "- Independence Day (action, science-fiction, drama; 1996)\n",
    "- Braveheart (biography, drama, epic; 1995)\n",
    "These are all famous Hollywood movies produced around the 1990s. Amongst all the options, the only movie similar to these ones seems to be Forrest Gump (comedy, drama, romance; 1994). So the answer is (C).\n",
    "\n",
    "{query}\n",
    "\n",
    "### Answer\n",
    "Assistant:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\n",
    "        \"query\"\n",
    "    ],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72ec30-71f4-45c4-aa7b-59ba38267852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=local_llm,\n",
    "    prompt=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00e92f-f65a-419e-9d53-bdbcce7c9018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = llm_chain.run(\n",
    "    query=\"\"\"\n",
    "Human: Find a movie similar to Minority Report, Total Recall, Inside Out, Forrest Gump:\n",
    "Options:\n",
    "(A) Phenomena\n",
    "(B) Lilting\n",
    "(C) Catwoman\n",
    "(D) Edge of Tomorrow\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955eddfd-0e1d-4eab-8be8-9bfc49350f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d2d249-cfdd-4cd3-b545-ecd089419bdd",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6666a-d662-415b-bb84-d5f3dac9def5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Reference: https://www.pinecone.io/learn/series/langchain/langchain-prompt-templates/\n",
    "Reference: https://www.promptingguide.ai/techniques/cot\n",
    "Reference: https://github.com/FranxYao/chain-of-thought-hub/blob/main/BBH/lib_prompt_multiround_claude_instant/movie_recommendation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe55f4f-8c0f-4c3b-9f37-5dc783b31bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
